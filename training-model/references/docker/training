# BUILD (in docker):
# docker$ docker build -f training  --tag training_bib_ref . 
# 
# RUN (in the project root):
# mkdir output && chmod o+rwx output
# docker run --runtime=nvidia --shm-size 2G --network host --rm -it --mount type=bind,source=$(pwd),target=/opt/ml/code training_bib_ref:latest
#
#FROM mambaorg/micromamba:0.24.0
FROM mambaorg/micromamba:focal-cuda-11.7.1

arg cuda_version=11.7
arg python_version=3.10.8
arg spacy_version=3.4.3
arg torch_version=1.13.0

ARG model_dir=/opt/ml/model
ARG app_dir=/opt/ml/code

WORKDIR ${app_dir}


# define requirements: https://hub.docker.com/r/mambaorg/micromamba 
RUN printf "name: base\n\
channels:\n\
  - pytorch\n\
  - conda-forge\n\
dependencies:\n\
  - cudatoolkit=${cuda_version}\n\
  - pytorch=${torch_version}\n\
  - python=${python_version}\n\
  - spacy=${spacy_version}\n\
  - spacy-lookups-data\n\
  - spacy-transformers\n\
  - sentencepiece\n\
  - cupy\n\
  - ipython\n\
  - jupyter\n\
  - scikit-learn\n\
  - nodejs==16.14.2\n\
" > /tmp/env.yaml
RUN cat /tmp/env.yaml
# install
#
RUN micromamba install -y -n base -f /tmp/env.yaml && \
    micromamba clean --all --yes

ARG MAMBA_DOCKERFILE_ACTIVATE=1

RUN spacy download en_core_web_lg
